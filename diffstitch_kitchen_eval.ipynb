{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9be946-37eb-45ce-95be-c57ad72efe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/cc1547/miniconda3/envs/diffstitch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "import os\n",
    "from diffuser.utils.arrays import to_torch, to_np, to_device\n",
    "from diffuser.datasets.d4rl import suppress_output\n",
    "import diffuser.utils as utils\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from ml_logger import logger\n",
    "import importlib\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89d2c59-c40d-4cf0-921b-a8364a0f9449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/config ] Imported diffuser.datasets:CondSequenceDataset\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.datasets.sequence.CondSequenceDataset'>\n",
      "    aug_data_file: None\n",
      "    data_file: None\n",
      "    env: kitchen-partial-v0\n",
      "    horizon: 40\n",
      "    include_returns: True\n",
      "    jump: 1\n",
      "    max_path_length: 280\n",
      "    normalizer: CDFNormalizer\n",
      "    preprocess_fns: []\n",
      "    returns_scale: 1.0\n",
      "    stitch: False\n",
      "    task_data: True\n",
      "    use_padding: True\n",
      "\n",
      "[ utils/config ] Saved config to: dataset_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.utils:MuJoCoRenderer\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.utils.rendering.MuJoCoRenderer'>\n",
      "    env: kitchen-partial-v0\n",
      "\n",
      "[ utils/config ] Saved config to: render_config.pkl\n",
      "\n",
      "class =  <class 'diffuser.datasets.sequence.CondSequenceDataset'>\n",
      "kwargs =  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "/common/home/cc1547/miniconda3/envs/diffstitch/lib/python3.8/site-packages/glfw/__init__.py:914: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 28 2023 23:51:11\n",
      "load datafile: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 28.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/buffer ] Finalized replay buffer | 2098 episodes\n",
      "[ datasets/buffer ] Fields:\n",
      "    observations: (2098, 280, 30)\n",
      "    rewards: (2098, 280, 1)\n",
      "    actions: (2098, 280, 9)\n",
      "    terminals: (2098, 280, 1)\n",
      "    normed_observations: (2098, 280, 30)\n",
      "    normed_actions: (2098, 280, 9)\n"
     ]
    }
   ],
   "source": [
    "def import_config(config_name):\n",
    "    module_path = f\"detail_configs.{config_name}\"\n",
    "    try:\n",
    "        module = importlib.import_module(module_path)\n",
    "        return module.Config\n",
    "    except ImportError:\n",
    "        print(f\"Error: Module '{config_name}' not found or has no 'Config' attribute.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "Config = import_config(\"kitchen_partial_task\")\n",
    "\n",
    "dataset_config = utils.Config(\n",
    "    \"datasets.CondSequenceDataset\",\n",
    "    savepath=\"dataset_config.pkl\",\n",
    "    env=Config.dataset,\n",
    "    horizon=Config.horizon,\n",
    "    normalizer=Config.normalizer,\n",
    "    preprocess_fns=Config.preprocess_fns,\n",
    "    use_padding=Config.use_padding,\n",
    "    max_path_length=Config.max_path_length,\n",
    "    include_returns=Config.include_returns,\n",
    "    returns_scale=Config.returns_scale,\n",
    "    data_file=Config.data_file,\n",
    "    stitch=Config.stitch,\n",
    "    task_data=True,\n",
    "    aug_data_file=None,\n",
    "    jump=1,\n",
    ")\n",
    "render_config = utils.Config(\n",
    "    Config.renderer,\n",
    "    savepath=\"render_config.pkl\",\n",
    "    env=Config.dataset,\n",
    ")\n",
    "\n",
    "dataset = dataset_config()\n",
    "renderer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e127553-6996-487f-a6fe-aad8e40ef898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "loadpath =  /common/users/cc1547/projects/rainbow/diffstitch/diffuser/kitchen-partial-v0/default_inv/predict_epsilon_100_1000000.0/dropout_0.25/kitchen_partial/task/40/round3/checkpoint\n",
      "\n",
      "[ utils/config ] Imported diffuser.models:TemporalUnet\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
      "    cond_dim: 30\n",
      "    dim: 128\n",
      "    dim_mults: (1, 4, 8)\n",
      "    horizon: 40\n",
      "    returns_condition: True\n",
      "    transition_dim: 30\n",
      "\n",
      "[ utils/config ] Saved config to: model_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.models:GaussianInvDynDiffusion\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.models.diffusion.GaussianInvDynDiffusion'>\n",
      "    action_dim: 9\n",
      "    action_weight: 10\n",
      "    clip_denoised: True\n",
      "    condition_guidance_w: 1.2\n",
      "    hidden_dim: 256\n",
      "    horizon: 40\n",
      "    loss_discount: 1\n",
      "    loss_type: l2\n",
      "    loss_weights: None\n",
      "    n_timesteps: 100\n",
      "    observation_dim: 30\n",
      "    predict_epsilon: True\n",
      "    returns_condition: True\n",
      "\n",
      "[ utils/config ] Saved config to: diffusion_config.pkl\n",
      "\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.utils.training.Trainer'>\n",
      "    bucket: /common/users/cc1547/projects/rainbow/diffstitch/diffuser/\n",
      "    ema_decay: 0.995\n",
      "    gradient_accumulate_every: 2\n",
      "    label_freq: 200000\n",
      "    log_freq: 1000\n",
      "    n_reference: 8\n",
      "    n_samples: 10\n",
      "    sample_freq: 10000\n",
      "    save_freq: 100000\n",
      "    save_parallel: False\n",
      "    train_batch_size: 32\n",
      "    train_device: cuda:0\n",
      "    train_lr: 0.0002\n",
      "\n",
      "[ utils/config ] Saved config to: trainer_config.pkl\n",
      "\n",
      "class =  <class 'diffuser.models.temporal.TemporalUnet'>\n",
      "kwargs =  {}\n",
      "[ models/temporal ] Channel dimensions: [(30, 128), (128, 512), (512, 1024)]\n",
      "[(30, 128), (128, 512), (512, 1024)]\n",
      "class =  <class 'diffuser.models.diffusion.GaussianInvDynDiffusion'>\n",
      "kwargs =  {}\n",
      "class =  <class 'diffuser.utils.training.Trainer'>\n",
      "kwargs =  {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadpath = os.path.join(Config.bucket, Config.dataset, Config.prefix, \"checkpoint\")\n",
    "loadpath = '/common/users/cc1547/projects/rainbow/diffstitch/diffuser/kitchen-partial-v0/default_inv/' \\\n",
    "'predict_epsilon_100_1000000.0/dropout_0.25/kitchen_partial/task/40/round3/checkpoint'\n",
    "\n",
    "print(\"\\n\\nloadpath = \", loadpath, end=\"\\n\\n\")\n",
    "\n",
    "loadpath = os.path.join(loadpath, f\"state_1000000.pt\")\n",
    "state_dict = torch.load(loadpath, map_location=Config.device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "utils.set_seed(Config.seed)\n",
    "random.seed(Config.seed)\n",
    "\n",
    "obs_dim = observation_dim = dataset.observation_dim\n",
    "action_dim = dataset.action_dim\n",
    "transition_dim = observation_dim\n",
    "\n",
    "model_config = utils.Config(\n",
    "    Config.model,\n",
    "    savepath=\"model_config.pkl\",\n",
    "    horizon=Config.horizon,\n",
    "    transition_dim=transition_dim,\n",
    "    cond_dim=observation_dim,\n",
    "    dim_mults=Config.dim_mults,\n",
    "    dim=Config.dim,\n",
    "    returns_condition=Config.returns_condition,\n",
    "    device=Config.device,\n",
    ")\n",
    "\n",
    "diffusion_config = utils.Config(\n",
    "    Config.diffusion,\n",
    "    savepath=\"diffusion_config.pkl\",\n",
    "    horizon=Config.horizon,\n",
    "    observation_dim=observation_dim,\n",
    "    action_dim=action_dim,\n",
    "    n_timesteps=Config.n_diffusion_steps,\n",
    "    loss_type=Config.loss_type,\n",
    "    clip_denoised=Config.clip_denoised,\n",
    "    predict_epsilon=Config.predict_epsilon,\n",
    "    hidden_dim=Config.hidden_dim,\n",
    "    ## loss weighting\n",
    "    action_weight=Config.action_weight,\n",
    "    loss_weights=Config.loss_weights,\n",
    "    loss_discount=Config.loss_discount,\n",
    "    returns_condition=Config.returns_condition,\n",
    "    device=Config.device,\n",
    "    condition_guidance_w=Config.condition_guidance_w,\n",
    ")\n",
    "\n",
    "trainer_config = utils.Config(\n",
    "    utils.Trainer,\n",
    "    savepath=\"trainer_config.pkl\",\n",
    "    train_batch_size=Config.batch_size,\n",
    "    train_lr=Config.learning_rate,\n",
    "    gradient_accumulate_every=Config.gradient_accumulate_every,\n",
    "    ema_decay=Config.ema_decay,\n",
    "    sample_freq=Config.sample_freq,\n",
    "    save_freq=Config.save_freq,\n",
    "    log_freq=Config.log_freq,\n",
    "    label_freq=int(Config.n_train_steps // Config.n_saves),\n",
    "    save_parallel=Config.save_parallel,\n",
    "    bucket=Config.bucket,\n",
    "    n_reference=Config.n_reference,\n",
    "    n_samples=Config.n_samples,\n",
    "    train_device=Config.device,\n",
    ")\n",
    "model = model_config()\n",
    "diffusion = diffusion_config(model)\n",
    "trainer = trainer_config(diffusion, dataset, renderer)\n",
    "# logger.print(utils.report_parameters(model), color='green')\n",
    "trainer.step = state_dict[\"step\"]\n",
    "trainer.model.load_state_dict(state_dict[\"model\"])\n",
    "trainer.ema_model.load_state_dict(state_dict[\"ema\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4a8d38-3f65-487a-988f-c82b025881d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = Config.horizon\n",
    "device = Config.device\n",
    "dynamics_deviate = 0.5\n",
    "test_ret = Config.test_ret\n",
    "sample_optim_batch = 1000\n",
    "dreamer_similarity = 1.5\n",
    "stitch_L = 30\n",
    "stitch_R = 60\n",
    "obs_dim = observation_dim\n",
    "dream_len = Config.dream_len\n",
    "stitch_batch_size = 400\n",
    "\n",
    "num_eval = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a802180-177a-4987-8083-d74945bba6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 0.7 =================\n",
      "\u001b[32maverage_ep_reward: 0.0, std_ep_reward: 0.0\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │         0.         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │         0.         │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 0.8 =================\n",
      "\u001b[32maverage_ep_reward: 0.2, std_ep_reward: 0.4000000000000001\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │        0.2         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │        0.4         │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 2.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 0.9 =================\n",
      "\u001b[32maverage_ep_reward: 0.2, std_ep_reward: 0.6000000000000001\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │        0.2         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │        0.6         │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 1.0 =================\n",
      "\u001b[32maverage_ep_reward: 0.0, std_ep_reward: 0.0\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │         0.         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │         0.         │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_ret = [0.7,0.8,0.9,1.]\n",
    "total_rewards = []\n",
    "for test_r in test_ret:\n",
    "    returns = to_device(test_r * torch.ones(num_eval, 1), Config.device)\n",
    "    \n",
    "    env_list = [gym.make(Config.dataset) for _ in range(num_eval)]\n",
    "    dones = [False for _ in range(num_eval)]\n",
    "    episode_rewards = [0 for _ in range(num_eval)]\n",
    "    \n",
    "    assert trainer.ema_model.condition_guidance_w == Config.condition_guidance_w\n",
    "    \n",
    "    \n",
    "    \n",
    "    obs_list = [env.reset()[None, :30] for env in env_list]\n",
    "    obs = np.stack(obs_list, axis=0)\n",
    "    while sum(dones) < num_eval:\n",
    "    \n",
    "        state_normed = dataset.normalizer.normalize(obs, \"observations\")\n",
    "    \n",
    "        cond = np.ones(shape=(num_eval, horizon, 2 * obs_dim))\n",
    "        cond[:, :, obs_dim:] = 0\n",
    "        cond[:, :1, :obs_dim] = 0\n",
    "        cond[:, :1, obs_dim:] = state_normed\n",
    "    \n",
    "        conditions = torch.tensor(cond).to(device)\n",
    "    \n",
    "        samples = trainer.ema_model.conditional_sample(\n",
    "            conditions, returns=returns, verbose=False\n",
    "        )  # shape is [1, 100, 11]\n",
    "        obs_comb = torch.cat([samples[:, 0, :], samples[:, 1, :]], dim=-1)\n",
    "        obs_comb = obs_comb.reshape(-1, 2 * obs_dim)\n",
    "        action = trainer.ema_model.inv_model(obs_comb)\n",
    "    \n",
    "        samples = to_np(samples)\n",
    "        action = to_np(action)\n",
    "        action = dataset.normalizer.unnormalize(action, \"actions\")\n",
    "    \n",
    "        obs_list = []\n",
    "        for i in range(num_eval):\n",
    "            this_obs, this_reward, this_done, _ = env_list[i].step(action[i])\n",
    "            obs_list.append(this_obs[None, :30])\n",
    "    \n",
    "            if not dones[i]:\n",
    "                episode_rewards[i] += this_reward\n",
    "    \n",
    "                if this_done:\n",
    "                    dones[i] = 1\n",
    "                    logger.print(f\"Episode ({i}): {episode_rewards[i]}\", color=\"green\")\n",
    "    \n",
    "        obs = np.stack(obs_list, axis=0)\n",
    "    \n",
    "    episode_rewards = np.array(episode_rewards)\n",
    "    total_rewards.append(episode_rewards)\n",
    "    print(f' ============== test return:\\t {test_r} =================')\n",
    "    \n",
    "    logger.print(\n",
    "        f\"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "    logger.log_metrics_summary(\n",
    "        {\n",
    "            \"average_ep_reward\": np.mean(episode_rewards),\n",
    "            \"std_ep_reward\": np.std(episode_rewards),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    [env.close() for env in env_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071e16bd-e59c-4164-af4f-df433b9bcbc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtotal_rewards\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_rewards' is not defined"
     ]
    }
   ],
   "source": [
    "len(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90c071-2109-46d0-bb82-7f92b2475081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
