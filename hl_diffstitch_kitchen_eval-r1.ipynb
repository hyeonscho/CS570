{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d84aa1-c2e4-409c-a39b-6f4fe8eeedc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/cc1547/miniconda3/envs/diffstitch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "import os\n",
    "from diffuser.utils.arrays import to_torch, to_np, to_device\n",
    "from diffuser.datasets.d4rl import suppress_output\n",
    "import diffuser.utils as utils\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from ml_logger import logger\n",
    "import importlib\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe67460d-3e4c-409c-bd33-2ee2848ba65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_config(config_name):\n",
    "    module_path = f\"detail_configs.{config_name}\"\n",
    "    try:\n",
    "        module = importlib.import_module(module_path)\n",
    "        return module.Config\n",
    "    except ImportError:\n",
    "        print(f\"Error: Module '{config_name}' not found or has no 'Config' attribute.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "Config = import_config(\"kitchen_partial_hl_r1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cac441-664d-40ad-8dc7-150835aa0b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/config ] Imported diffuser.datasets:CondSequenceDataset\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.datasets.sequence.CondSequenceDataset'>\n",
      "    aug_data_file: None\n",
      "    data_file: None\n",
      "    env: kitchen-partial-v0\n",
      "    horizon: 160\n",
      "    include_returns: True\n",
      "    jump: 1\n",
      "    max_path_length: 260\n",
      "    normalizer: CDFNormalizer\n",
      "    preprocess_fns: []\n",
      "    returns_scale: 1.0\n",
      "    stitch: False\n",
      "    task_data: True\n",
      "    use_padding: True\n",
      "\n",
      "[ utils/config ] Saved config to: dataset_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.datasets:CondSequenceDataset\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.datasets.sequence.CondSequenceDataset'>\n",
      "    aug_data_file: /common/users/cc1547/dataset/rainbow/stitching_kitchen/round1_stitch_kitchen_partial_H40-v1.pkl\n",
      "    data_file: None\n",
      "    env: kitchen-partial-v0\n",
      "    horizon: 160\n",
      "    include_returns: True\n",
      "    jump: 10\n",
      "    max_path_length: 260\n",
      "    normalizer: CDFNormalizer\n",
      "    preprocess_fns: []\n",
      "    returns_scale: 1.0\n",
      "    stitch: False\n",
      "    task_data: True\n",
      "    use_padding: True\n",
      "\n",
      "[ utils/config ] Saved config to: dataset_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.utils:MuJoCoRenderer\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.utils.rendering.MuJoCoRenderer'>\n",
      "    env: kitchen-partial-v0\n",
      "\n",
      "[ utils/config ] Saved config to: render_config.pkl\n",
      "\n",
      "class =  <class 'diffuser.datasets.sequence.CondSequenceDataset'>\n",
      "kwargs =  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "/common/home/cc1547/miniconda3/envs/diffstitch/lib/python3.8/site-packages/glfw/__init__.py:914: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 28 2023 23:51:11\n",
      "load datafile: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/buffer ] Finalized replay buffer | 2098 episodes\n",
      "[ datasets/buffer ] Fields:\n",
      "    observations: (2098, 260, 30)\n",
      "    rewards: (2098, 260, 1)\n",
      "    actions: (2098, 260, 9)\n",
      "    terminals: (2098, 260, 1)\n",
      "    normed_observations: (2098, 260, 30)\n",
      "    normed_actions: (2098, 260, 9)\n",
      "class =  <class 'diffuser.datasets.sequence.CondSequenceDataset'>\n",
      "kwargs =  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/buffer ] Finalized replay buffer | 3395 episodes\n",
      "[ datasets/buffer ] Fields:\n",
      "    observations: (3395, 260, 30)\n",
      "    rewards: (3395, 260, 1)\n",
      "    actions: (3395, 260, 9)\n",
      "    terminals: (3395, 260, 1)\n",
      "    normed_observations: (3395, 260, 30)\n",
      "    normed_actions: (3395, 260, 9)\n"
     ]
    }
   ],
   "source": [
    "ll_dataset_config = utils.Config(\n",
    "    \"datasets.CondSequenceDataset\",\n",
    "    savepath=\"dataset_config.pkl\",\n",
    "    env=Config.dataset,\n",
    "    horizon=Config.horizon,\n",
    "    normalizer=Config.normalizer,\n",
    "    preprocess_fns=Config.preprocess_fns,\n",
    "    use_padding=Config.use_padding,\n",
    "    max_path_length=Config.max_path_length,\n",
    "    include_returns=Config.include_returns,\n",
    "    returns_scale=Config.returns_scale,\n",
    "    data_file=Config.data_file,\n",
    "    stitch=Config.stitch,\n",
    "    task_data=True,\n",
    "    aug_data_file=None,\n",
    "    jump=1,\n",
    ")\n",
    "\n",
    "hl_dataset_config = utils.Config(\n",
    "    \"datasets.CondSequenceDataset\",\n",
    "    savepath=\"dataset_config.pkl\",\n",
    "    env=Config.dataset,\n",
    "    horizon=Config.horizon,\n",
    "    normalizer=Config.normalizer,\n",
    "    preprocess_fns=Config.preprocess_fns,\n",
    "    use_padding=Config.use_padding,\n",
    "    max_path_length=Config.max_path_length,\n",
    "    include_returns=Config.include_returns,\n",
    "    returns_scale=Config.returns_scale,\n",
    "    data_file=Config.data_file,\n",
    "    stitch=Config.stitch,\n",
    "    task_data=Config.task_data,\n",
    "    aug_data_file=Config.aug_data_file,\n",
    "    jump=Config.jump,\n",
    ")\n",
    "render_config = utils.Config(\n",
    "    Config.renderer,\n",
    "    savepath=\"render_config.pkl\",\n",
    "    env=Config.dataset,\n",
    ")\n",
    "\n",
    "ll_dataset = ll_dataset_config()\n",
    "hl_dataset = hl_dataset_config()\n",
    "renderer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae4beae-d92f-468d-bf66-165e5431ad42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/config ] Imported diffuser.models:TemporalUnet\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
      "    cond_dim: 30\n",
      "    dim: 128\n",
      "    dim_mults: (1, 4, 8)\n",
      "    horizon: 160\n",
      "    returns_condition: True\n",
      "    transition_dim: 30\n",
      "\n",
      "[ utils/config ] Saved config to: model_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.models:TemporalUnet\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
      "    cond_dim: 30\n",
      "    dim: 128\n",
      "    dim_mults: (1, 4, 8)\n",
      "    horizon: 160\n",
      "    returns_condition: True\n",
      "    transition_dim: 30\n",
      "\n",
      "[ utils/config ] Saved config to: model_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.models:GaussianInvDynDiffusion\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.models.diffusion.GaussianInvDynDiffusion'>\n",
      "    action_dim: 9\n",
      "    action_weight: 10\n",
      "    clip_denoised: True\n",
      "    condition_guidance_w: 1.2\n",
      "    hidden_dim: 256\n",
      "    horizon: 16\n",
      "    loss_discount: 1\n",
      "    loss_type: l2\n",
      "    loss_weights: None\n",
      "    n_timesteps: 100\n",
      "    observation_dim: 30\n",
      "    predict_epsilon: True\n",
      "    returns_condition: True\n",
      "\n",
      "[ utils/config ] Saved config to: diffusion_config.pkl\n",
      "\n",
      "[ utils/config ] Imported diffuser.models:GaussianInvDynDiffusion\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.models.diffusion.GaussianInvDynDiffusion'>\n",
      "    action_dim: 9\n",
      "    action_weight: 10\n",
      "    clip_denoised: True\n",
      "    condition_guidance_w: 1.2\n",
      "    hidden_dim: 256\n",
      "    horizon: 40\n",
      "    loss_discount: 1\n",
      "    loss_type: l2\n",
      "    loss_weights: None\n",
      "    n_timesteps: 100\n",
      "    observation_dim: 30\n",
      "    predict_epsilon: True\n",
      "    returns_condition: True\n",
      "\n",
      "[ utils/config ] Saved config to: diffusion_config.pkl\n",
      "\n",
      "\n",
      "[utils/config ] Config: <class 'diffuser.utils.training.Trainer'>\n",
      "    bucket: /common/users/cc1547/projects/rainbow/diffstitch/diffuser/\n",
      "    ema_decay: 0.995\n",
      "    gradient_accumulate_every: 2\n",
      "    label_freq: 200000\n",
      "    log_freq: 1000\n",
      "    n_reference: 8\n",
      "    n_samples: 10\n",
      "    sample_freq: 10000\n",
      "    save_freq: 100000\n",
      "    save_parallel: False\n",
      "    train_batch_size: 32\n",
      "    train_device: cuda:0\n",
      "    train_lr: 0.0002\n",
      "\n",
      "[ utils/config ] Saved config to: trainer_config.pkl\n",
      "\n",
      "class =  <class 'diffuser.models.temporal.TemporalUnet'>\n",
      "kwargs =  {}\n",
      "[ models/temporal ] Channel dimensions: [(30, 128), (128, 512), (512, 1024)]\n",
      "[(30, 128), (128, 512), (512, 1024)]\n",
      "class =  <class 'diffuser.models.diffusion.GaussianInvDynDiffusion'>\n",
      "kwargs =  {}\n",
      "class =  <class 'diffuser.utils.training.Trainer'>\n",
      "kwargs =  {}\n",
      "class =  <class 'diffuser.models.temporal.TemporalUnet'>\n",
      "kwargs =  {}\n",
      "[ models/temporal ] Channel dimensions: [(30, 128), (128, 512), (512, 1024)]\n",
      "[(30, 128), (128, 512), (512, 1024)]\n",
      "class =  <class 'diffuser.models.diffusion.GaussianInvDynDiffusion'>\n",
      "kwargs =  {}\n",
      "class =  <class 'diffuser.utils.training.Trainer'>\n",
      "kwargs =  {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "utils.set_seed(Config.seed)\n",
    "random.seed(Config.seed)\n",
    "\n",
    "obs_dim = observation_dim = hl_dataset.observation_dim\n",
    "action_dim = hl_dataset.action_dim\n",
    "transition_dim = observation_dim\n",
    "\n",
    "hl_model_config = utils.Config(\n",
    "    Config.model,\n",
    "    savepath=\"model_config.pkl\",\n",
    "    horizon=Config.horizon,\n",
    "    transition_dim=transition_dim,\n",
    "    cond_dim=observation_dim,\n",
    "    dim_mults=Config.dim_mults,\n",
    "    dim=Config.dim,\n",
    "    returns_condition=Config.returns_condition,\n",
    "    device=Config.device,\n",
    ")\n",
    "\n",
    "ll_model_config = utils.Config(\n",
    "    Config.model,\n",
    "    savepath=\"model_config.pkl\",\n",
    "    horizon=Config.horizon,\n",
    "    transition_dim=transition_dim,\n",
    "    cond_dim=observation_dim,\n",
    "    dim_mults=Config.dim_mults,\n",
    "    dim=Config.dim,\n",
    "    returns_condition=Config.returns_condition,\n",
    "    device=Config.device,\n",
    ")\n",
    "\n",
    "hl_diffusion_config = utils.Config(\n",
    "    Config.diffusion,\n",
    "    savepath=\"diffusion_config.pkl\",\n",
    "    horizon=Config.horizon//Config.jump,\n",
    "    observation_dim=observation_dim,\n",
    "    action_dim=action_dim,\n",
    "    n_timesteps=Config.n_diffusion_steps,\n",
    "    loss_type=Config.loss_type,\n",
    "    clip_denoised=Config.clip_denoised,\n",
    "    predict_epsilon=Config.predict_epsilon,\n",
    "    hidden_dim=Config.hidden_dim,\n",
    "    ## loss weighting\n",
    "    action_weight=Config.action_weight,\n",
    "    loss_weights=Config.loss_weights,\n",
    "    loss_discount=Config.loss_discount,\n",
    "    returns_condition=Config.returns_condition,\n",
    "    device=Config.device,\n",
    "    condition_guidance_w=Config.condition_guidance_w,\n",
    ")\n",
    "\n",
    "ll_diffusion_config = utils.Config(\n",
    "    Config.diffusion,\n",
    "    savepath=\"diffusion_config.pkl\",\n",
    "    horizon=40,\n",
    "    observation_dim=observation_dim,\n",
    "    action_dim=action_dim,\n",
    "    n_timesteps=Config.n_diffusion_steps,\n",
    "    loss_type=Config.loss_type,\n",
    "    clip_denoised=Config.clip_denoised,\n",
    "    predict_epsilon=Config.predict_epsilon,\n",
    "    hidden_dim=Config.hidden_dim,\n",
    "    ## loss weighting\n",
    "    action_weight=Config.action_weight,\n",
    "    loss_weights=Config.loss_weights,\n",
    "    loss_discount=Config.loss_discount,\n",
    "    returns_condition=Config.returns_condition,\n",
    "    device=Config.device,\n",
    "    condition_guidance_w=Config.condition_guidance_w,\n",
    ")\n",
    "\n",
    "trainer_config = utils.Config(\n",
    "    utils.Trainer,\n",
    "    savepath=\"trainer_config.pkl\",\n",
    "    train_batch_size=Config.batch_size,\n",
    "    train_lr=Config.learning_rate,\n",
    "    gradient_accumulate_every=Config.gradient_accumulate_every,\n",
    "    ema_decay=Config.ema_decay,\n",
    "    sample_freq=Config.sample_freq,\n",
    "    save_freq=Config.save_freq,\n",
    "    log_freq=Config.log_freq,\n",
    "    label_freq=int(Config.n_train_steps // Config.n_saves),\n",
    "    save_parallel=Config.save_parallel,\n",
    "    bucket=Config.bucket,\n",
    "    n_reference=Config.n_reference,\n",
    "    n_samples=Config.n_samples,\n",
    "    train_device=Config.device,\n",
    ")\n",
    "ll_model = ll_model_config()\n",
    "ll_diffusion = ll_diffusion_config(ll_model)\n",
    "ll_trainer = trainer_config(ll_diffusion, ll_dataset, renderer)\n",
    "\n",
    "ll_loadpath = '/common/users/cc1547/projects/rainbow/diffstitch/diffuser/kitchen-partial-v0/default_inv/' \\\n",
    "'predict_epsilon_100_1000000.0/dropout_0.25/kitchen_partial/task/40/round3/checkpoint'\n",
    "ll_loadpath = os.path.join(ll_loadpath, f\"state_1000000.pt\")\n",
    "\n",
    "state_dict = torch.load(ll_loadpath, map_location=Config.device)\n",
    "ll_trainer.step = state_dict[\"step\"]\n",
    "ll_trainer.model.load_state_dict(state_dict[\"model\"])\n",
    "ll_trainer.ema_model.load_state_dict(state_dict[\"ema\"])\n",
    "\n",
    "hl_model = hl_model_config()\n",
    "hl_diffusion = hl_diffusion_config(hl_model)\n",
    "hl_trainer = trainer_config(hl_diffusion, hl_dataset, renderer)\n",
    "\n",
    "hl_loadpath = '/common/users/cc1547/projects/rainbow/diffstitch/diffuser/kitchen-partial-v0/default_inv/' \\\n",
    "'predict_epsilon_100_1000000.0/dropout_0.25/kitchen/hl160/round3/checkpoint'\n",
    "hl_loadpath = os.path.join(hl_loadpath, f\"state_1000000.pt\")\n",
    "\n",
    "state_dict = torch.load(hl_loadpath, map_location=Config.device)\n",
    "hl_trainer.step = state_dict[\"step\"]\n",
    "hl_trainer.model.load_state_dict(state_dict[\"model\"])\n",
    "hl_trainer.ema_model.load_state_dict(state_dict[\"ema\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c498fbd-ec0b-4c61-9921-350eba33d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_horizon = Config.horizon//Config.jump\n",
    "jump = Config.jump\n",
    "ll_horizon = 40\n",
    "device = Config.device\n",
    "num_eval = 10\n",
    "obs_dim = observation_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5717f3-8355-4cb0-aa35-234018c46cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 1.0\u001b[0m\n",
      " ============== test return:\t 0.2 =================\n",
      "\u001b[32maverage_ep_reward: 0.6, std_ep_reward: 0.48989794855663565\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │        0.6         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │        0.49        │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 0.3 =================\n",
      "\u001b[32maverage_ep_reward: 0.4, std_ep_reward: 0.48989794855663565\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │        0.4         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │        0.49        │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 0.4 =================\n",
      "\u001b[32maverage_ep_reward: 0.4, std_ep_reward: 0.48989794855663565\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │        0.4         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │        0.49        │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "\u001b[32mEpisode (0): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (1): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (2): 1.0\u001b[0m\n",
      "\u001b[32mEpisode (3): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (4): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (5): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (6): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (7): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (8): 0.0\u001b[0m\n",
      "\u001b[32mEpisode (9): 0.0\u001b[0m\n",
      " ============== test return:\t 0.5 =================\n",
      "\u001b[32maverage_ep_reward: 0.2, std_ep_reward: 0.4000000000000001\u001b[0m\n",
      "╒════════════════════╤════════════════════╕\n",
      "│ average ep reward  │        0.2         │\n",
      "├────────────────────┼────────────────────┤\n",
      "│   std ep reward    │        0.4         │\n",
      "╘════════════════════╧════════════════════╛\n",
      "\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# test_ret = [0.8,0.85,0.9,0.95,1.]\n",
    "ll_test_ret = 0.85\n",
    "\n",
    "\n",
    "hl_test_ret = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "total_rewards = []\n",
    "for hl_test_r in hl_test_ret:\n",
    "    hl_returns = to_device(hl_test_r * torch.ones(num_eval, 1), Config.device)\n",
    "    ll_returns = to_device(hl_test_r * torch.ones(num_eval, 1), Config.device)\n",
    "    \n",
    "    \n",
    "    env_list = [gym.make(Config.dataset) for _ in range(num_eval)]\n",
    "    dones = [False for _ in range(num_eval)]\n",
    "    episode_rewards = [0 for _ in range(num_eval)]\n",
    "    \n",
    "    assert ll_trainer.ema_model.condition_guidance_w == Config.condition_guidance_w\n",
    "    assert hl_trainer.ema_model.condition_guidance_w == Config.condition_guidance_w\n",
    "    \n",
    "    \n",
    "    \n",
    "    obs_list = [env.reset()[None, :30] for env in env_list]\n",
    "    obs = np.stack(obs_list, axis=0)\n",
    "    while sum(dones) < num_eval:\n",
    "    \n",
    "        state_normed = hl_dataset.normalizer.normalize(obs, 'observations')\n",
    "        hl_cond = np.ones(shape=(num_eval, hl_horizon, 2 * obs_dim))\n",
    "        hl_cond[:, :, obs_dim:] = 0\n",
    "        hl_cond[:, :1, :obs_dim] = 0\n",
    "        hl_cond[:, :1, obs_dim:] = state_normed\n",
    "        \n",
    "        hl_conditions = torch.tensor(hl_cond).to(device)\n",
    "        \n",
    "        hl_samples = hl_trainer.ema_model.conditional_sample(\n",
    "            hl_conditions, returns=hl_returns, verbose=False\n",
    "        )  # shape is [1, 100, 11]\n",
    "        hl_samples = to_np(hl_samples)\n",
    "        \n",
    "        ll_cond = np.ones(shape=(num_eval, ll_horizon, 2 * obs_dim))\n",
    "        ll_cond[:, :, obs_dim:] = 0\n",
    "        ll_cond[:, ::jump, :obs_dim] = 0\n",
    "        ll_cond[:, ::jump, obs_dim:] = hl_samples[:, :ll_horizon//jump]\n",
    "        ll_conditions = torch.tensor(ll_cond).to(device)\n",
    "        \n",
    "        ll_samples = ll_trainer.ema_model.conditional_sample(\n",
    "            ll_conditions, returns=ll_returns, verbose=False\n",
    "        )\n",
    "        \n",
    "        obs_comb = torch.cat([ll_samples[:, 0, :], ll_samples[:, 1, :]], dim=-1)\n",
    "        obs_comb = obs_comb.reshape(-1, 2 * obs_dim)\n",
    "        action = ll_trainer.ema_model.inv_model(obs_comb)\n",
    "        \n",
    "        action = to_np(action)\n",
    "        action = ll_dataset.normalizer.unnormalize(action, \"actions\")\n",
    "    \n",
    "        obs_list = []\n",
    "        for i in range(num_eval):\n",
    "            this_obs, this_reward, this_done, _ = env_list[i].step(action[i])\n",
    "            obs_list.append(this_obs[None, :30])\n",
    "    \n",
    "            if not dones[i]:\n",
    "                episode_rewards[i] += this_reward\n",
    "    \n",
    "                if this_done:\n",
    "                    dones[i] = 1\n",
    "                    logger.print(f\"Episode ({i}): {episode_rewards[i]}\", color=\"green\")\n",
    "    \n",
    "        obs = np.stack(obs_list, axis=0)\n",
    "    \n",
    "    episode_rewards = np.array(episode_rewards)\n",
    "    total_rewards.append(episode_rewards)\n",
    "    print(f' ============== test return:\\t {hl_test_r} =================')\n",
    "    \n",
    "    logger.print(\n",
    "        f\"average_ep_reward: {np.mean(episode_rewards)}, std_ep_reward: {np.std(episode_rewards)}\",\n",
    "        color=\"green\",\n",
    "    )\n",
    "    logger.log_metrics_summary(\n",
    "        {\n",
    "            \"average_ep_reward\": np.mean(episode_rewards),\n",
    "            \"std_ep_reward\": np.std(episode_rewards),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    [env.close() for env in env_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14bec5-2dbd-4aa0-bf03-e20fbf1ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53c5a3-4271-48a0-8a62-f21641f522e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
