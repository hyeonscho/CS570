{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bfa54-79a3-4b6c-9488-80a0f8e51bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from d4rl.pointmaze import q_iteration\n",
    "from d4rl.pointmaze.gridcraft import grid_env\n",
    "from d4rl.pointmaze.gridcraft import grid_spec\n",
    "\n",
    "\n",
    "ZEROS = np.zeros((2,), dtype=np.float32)\n",
    "ONES = np.zeros((2,), dtype=np.float32)\n",
    "\n",
    "\n",
    "class WaypointController(object):\n",
    "    def __init__(self, maze_str, solve_thresh=0.1, p_gain=10.0, d_gain=-1.0):\n",
    "        self.maze_str = maze_str\n",
    "        self._target = -1000 * ONES\n",
    "\n",
    "        self.p_gain = p_gain\n",
    "        self.d_gain = d_gain\n",
    "        self.solve_thresh = solve_thresh\n",
    "        self.vel_thresh = 0.1\n",
    "\n",
    "        self._waypoint_idx = 0\n",
    "        self._waypoints = []\n",
    "        self._waypoint_prev_loc = ZEROS\n",
    "\n",
    "        self.env = grid_env.GridEnv(grid_spec.spec_from_string(maze_str))\n",
    "\n",
    "    def current_waypoint(self):\n",
    "        return self._waypoints[self._waypoint_idx]\n",
    "\n",
    "    def get_action(self, location, velocity, target):\n",
    "        if np.linalg.norm(self._target - np.array(self.gridify_state(target))) > 1e-3: \n",
    "            #print('New target!', target, 'old:', self._target)\n",
    "            self._new_target(location, target)\n",
    "\n",
    "        dist = np.linalg.norm(location - self._target)\n",
    "        vel = self._waypoint_prev_loc - location\n",
    "        vel_norm = np.linalg.norm(vel)\n",
    "        task_not_solved = (dist >= self.solve_thresh) or (vel_norm >= self.vel_thresh)\n",
    "\n",
    "        if task_not_solved:\n",
    "            next_wpnt = self._waypoints[self._waypoint_idx]\n",
    "        else:\n",
    "            next_wpnt = self._target\n",
    "\n",
    "        # Compute control\n",
    "        prop = next_wpnt - location\n",
    "        action = self.p_gain * prop + self.d_gain * velocity\n",
    "\n",
    "        dist_next_wpnt = np.linalg.norm(location - next_wpnt)\n",
    "        if task_not_solved and (dist_next_wpnt < self.solve_thresh) and (vel_norm<self.vel_thresh):\n",
    "            self._waypoint_idx += 1\n",
    "            if self._waypoint_idx == len(self._waypoints)-1:\n",
    "                assert np.linalg.norm(self._waypoints[self._waypoint_idx] - self._target) <= self.solve_thresh\n",
    "\n",
    "        self._waypoint_prev_loc = location\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "        return action, (not task_not_solved)\n",
    "\n",
    "    def gridify_state(self, state):\n",
    "        return (int(round(state[0])), int(round(state[1])))\n",
    "\n",
    "    def _new_target(self, start, target):\n",
    "        #print('Computing waypoints from %s to %s' % (start, target))\n",
    "        start = self.gridify_state(start)\n",
    "        start_idx = self.env.gs.xy_to_idx(start)\n",
    "        target = self.gridify_state(target)\n",
    "        target_idx = self.env.gs.xy_to_idx(target)\n",
    "        self._waypoint_idx = 0\n",
    "\n",
    "        self.env.gs[target] = grid_spec.REWARD\n",
    "        q_values = q_iteration.q_iteration(env=self.env, num_itrs=50, discount=0.99)\n",
    "        # compute waypoints by performing a rollout in the grid\n",
    "        max_ts = 100\n",
    "        s = start_idx\n",
    "        waypoints = []\n",
    "        for i in range(max_ts):\n",
    "            a = np.argmax(q_values[s])\n",
    "            new_s, reward = self.env.step_stateless(s, a)\n",
    "\n",
    "            waypoint = self.env.gs.idx_to_xy(new_s)\n",
    "            if new_s != target_idx:\n",
    "                waypoint = waypoint - np.random.uniform(size=(2,))*0.2\n",
    "            waypoints.append(waypoint)\n",
    "            s = new_s\n",
    "            if new_s == target_idx:\n",
    "                break\n",
    "        self.env.gs[target] = grid_spec.EMPTY\n",
    "        self._waypoints = waypoints\n",
    "        self._waypoint_prev_loc = start\n",
    "        self._target = target\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(q_iteration.__file__)\n",
    "    TEST_MAZE = \\\n",
    "            \"######\\\\\"+\\\n",
    "            \"#OOOO#\\\\\"+\\\n",
    "            \"#O##O#\\\\\"+\\\n",
    "            \"#OOOO#\\\\\"+\\\n",
    "            \"######\"\n",
    "    controller = WaypointController(TEST_MAZE)\n",
    "    start = np.array((1,1), dtype=np.float32)\n",
    "    target = np.array((4,3), dtype=np.float32)\n",
    "    act, done = controller.get_action(start, target)\n",
    "    print('wpt:', controller._waypoints)\n",
    "    print(act, done)\n",
    "    import pdb; pdb.set_trace()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94aee46-1958-49a4-914e-b032f2d59b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_env(env, sg_dict):\n",
    "    env.reset()\n",
    "    env.set_target(sg_dict['goal_cell'])\n",
    "    return env.reset_to_location(sg_dict['reset_cell'])\n",
    "\n",
    "\n",
    "# TODO: make the data saving as before not following d4rl\n",
    "# the controller is from d4rl\n",
    "\n",
    "# each episode not necessarily continue from the last step, that is why the dataset is not continuous\n",
    "def collect_short_dataset(env_name, num_data, seed=1127, verbose=True):\n",
    "    # seed\n",
    "    np.random.seed(seed)            \n",
    "    random.seed(seed)               \n",
    "    \n",
    "    # environment initialisation\n",
    "    env = datasets.load_environment(env_name)\n",
    "    maze = env.str_maze_spec\n",
    "    # seed\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "\n",
    "    controller = waypoint_controller.WaypointController(maze)\n",
    "    # get data collecting start state and goal pairs\n",
    "    train_start_state_goal = get_start_state_goal_pairs(env_name, env)\n",
    "\n",
    "    done = False\n",
    "    data = reset_data()\n",
    "    ts = 0\n",
    "    num_dc = len(train_start_state_goal)\n",
    "    episode_idx = 0\n",
    "    sg_dict = train_start_state_goal[ episode_idx % num_dc ]\n",
    "    # print(sg_dict)\n",
    "    obs = reset_env(env, sg_dict)\n",
    "\n",
    "    for _ in range(num_data):\n",
    "        pass\n",
    "    \n",
    "    while data_idx < int(num_data)-1:\n",
    "        # compute actions\n",
    "        position = obs[0:2]\n",
    "        velocity = obs[2:4]\n",
    "        act, done = controller.get_action(position, velocity, env._target)\n",
    "        if noisy:\n",
    "            act = act + np.random.randn(*act.shape)*0.5\n",
    "        act = np.clip(act, -1.0, 1.0)\n",
    "        \n",
    "        if ts >= max_episode_steps:\n",
    "            done = True\n",
    "        append_data(data, obs, act, env._target, done, env.sim.data)\n",
    "        # (s, a) in the dataset\n",
    "        \n",
    "        data_idx += 1\n",
    "        ns, _, _, _ = env.step(act)\n",
    "\n",
    "        if len(data['observations']) % 10000 == 0:\n",
    "            print(len(data['observations']))\n",
    "\n",
    "        ts += 1\n",
    "        if done:\n",
    "            env.set_target()\n",
    "            done = False\n",
    "            ts = 0\n",
    "        else:\n",
    "            s = ns\n",
    "\n",
    "#         if args.render:\n",
    "#             env.render()\n",
    "        \n",
    "        \n",
    "        if terminated or truncated:\n",
    "            if info['success']:\n",
    "                success_count += 1\n",
    "\n",
    "                observation_data[\"episode_id\"][data_idx] = episode_idx\n",
    "                observation_data[\"observation\"][data_idx] = obs[\"observation\"]\n",
    "                observation_data[\"achieved_goal\"][data_idx] = obs[\"achieved_goal\"]\n",
    "                observation_data[\"desired_goal\"][data_idx] = obs[\"desired_goal\"]\n",
    "                termination_data[data_idx] = terminated or truncated\n",
    "\n",
    "                data_idx += 1\n",
    "                episode_idx += 1\n",
    "                episode_start_idx = data_idx\n",
    "        \n",
    "            else:\n",
    "                data_idx = episode_start_idx\n",
    "                # print(f' === failed {episode_idx} ===')\n",
    "\n",
    "            sg_dict = train_start_state_goal[ episode_idx % num_dc ]\n",
    "            # print(sg_dict)\n",
    "\n",
    "            obs, _ = env.reset(options=sg_dict)\n",
    "\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"STEPS RECORDED:\", data_idx)\n",
    "                print(\"EPISODES RECORDED:\", episode_idx)\n",
    "                print(\"SUCCESS EPISODES RECORDED:\", success_count)\n",
    "\n",
    "    dataset = {\n",
    "        \"observations\":observation_data, \n",
    "        \"actions\":action_data, \n",
    "        \"terminations\":termination_data,\n",
    "        \"success_count\": success_count,\n",
    "        \"episode_count\": episode_idx,\n",
    "    }\n",
    "\n",
    "    return env, dataset\n",
    "    \n",
    "    \n",
    "collect_short_dataset(env_name, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28af3e-c8cf-47e5-bd1b-cf2eda265907",
   "metadata": {},
   "outputs": [],
   "source": [
    "maze_map = np.array(env.unwrapped.maze._maze_map)\n",
    "maze = env.unwrapped.maze\n",
    "_background = maze_map == 1\n",
    "\n",
    "\n",
    "train_start_state_goal = get_start_state_goal_pairs(dataset_name, env)\n",
    "\n",
    "for i in range(len(train_start_state_goal) // 4):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5), constrained_layout=True)\n",
    "\n",
    "    for idx, ax in enumerate(axes):\n",
    "        ax.imshow(\n",
    "            _background * 0.5,\n",
    "            cmap=plt.cm.binary,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "        )\n",
    "        # collected trajectory\n",
    "        obs = trjs[4*i + idx]['observations']['observation'][:, :2]\n",
    "        ij = cell_xy_to_rowcol(maze, obs) -0.5\n",
    "        colors = plt.cm.Blues(np.linspace(0.4, 1.0, len(ij)))\n",
    "        ax.scatter(ij[:, 1], ij[:, 0], s=10, c=colors)\n",
    "\n",
    "        # start and goal\n",
    "        goal_cell = train_start_state_goal[4*i + idx]['goal_cell']\n",
    "        reset_cell = train_start_state_goal[4*i + idx]['reset_cell']\n",
    "        ax.scatter(goal_cell[1], goal_cell[0], color='Red', s=100)\n",
    "        ax.scatter(reset_cell[1], reset_cell[0], color='Blue', s=100)\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b2272-85d6-4e26-bb50-6d142ddf60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_xy_to_rowcol(maze, xy_pos: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts a cell x and y coordinates to `(i,j)`\"\"\"\n",
    "\n",
    "    i = np.reshape((maze.y_map_center - xy_pos[:, 1]) / maze.maze_size_scaling, (-1, 1))\n",
    "    j = np.reshape((xy_pos[:, 0] + maze.x_map_center) / maze.maze_size_scaling, (-1, 1))\n",
    "\n",
    "    return np.concatenate([i,j], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eeeaf8-db9e-4cdc-adde-8729b50304e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE_BOUNDS = {\n",
    "    \"maze2d-umaze-v1\": (0, 5, 0, 5),\n",
    "    \"maze2d-medium-v1\": (0, 8, 0, 8),\n",
    "    \"maze2d-large-v1\": (0, 9, 0, 12),\n",
    "    \"maze2d-xxlarge-v1\": (0, 18, 0, 24),\n",
    "}\n",
    "\n",
    "\n",
    "class MazeRenderer:\n",
    "    def __init__(self, env):\n",
    "        if type(env) is str:\n",
    "            env = load_environment(env)\n",
    "            self._config = env._config\n",
    "            self._background = self._config != \" \"\n",
    "        self._remove_margins = False\n",
    "        self._extent = (0, 1, 1, 0)\n",
    "\n",
    "    def renders(self, observations, conditions=None, title=None):\n",
    "        plt.clf()\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(5, 5)\n",
    "        plt.imshow(\n",
    "            self._background * 0.5,\n",
    "            extent=self._extent,\n",
    "            cmap=plt.cm.binary,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "        )\n",
    "\n",
    "        path_length = len(observations)\n",
    "        colors = plt.cm.jet(np.linspace(0, 1, path_length))\n",
    "        plt.plot(observations[:, 1], observations[:, 0], c=\"black\", zorder=10)\n",
    "        plt.scatter(observations[:, 1], observations[:, 0], c=colors, zorder=20)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title)\n",
    "        img = plot2img(fig, remove_margins=self._remove_margins)\n",
    "        return img\n",
    "\n",
    "    def composite(self, savepath, paths, ncol=5, **kwargs):\n",
    "        \"\"\"\n",
    "        savepath : str\n",
    "        observations : [ n_paths x horizon x 2 ]\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            len(paths) % ncol == 0\n",
    "        ), \"Number of paths must be divisible by number of columns\"\n",
    "\n",
    "        images = []\n",
    "        for path, kw in zipkw(paths, **kwargs):\n",
    "            img = self.renders(*path, **kw)\n",
    "            images.append(img)\n",
    "        images = np.stack(images, axis=0)\n",
    "\n",
    "        nrow = len(images) // ncol\n",
    "        images = einops.rearrange(\n",
    "            images, \"(nrow ncol) H W C -> (nrow H) (ncol W) C\", nrow=nrow, ncol=ncol\n",
    "        )\n",
    "        imageio.imsave(savepath, images)\n",
    "        print(f\"Saved {len(paths)} samples to: {savepath}\")\n",
    "\n",
    "\n",
    "class Maze2dRenderer(MazeRenderer):\n",
    "    def __init__(self, env, observation_dim=None):\n",
    "        self.env_name = env\n",
    "        self.env = load_environment(env)\n",
    "        self._background = self.env.maze_arr == 10\n",
    "        self.observation_dim = np.prod(self.env.observation_space.shape)\n",
    "        self.action_dim = np.prod(self.env.action_space.shape)\n",
    "        self.goal = None\n",
    "        self._remove_margins = False\n",
    "        self._extent = (0, 1, 1, 0)\n",
    "\n",
    "    def renders(self, observations, conditions=None, **kwargs):\n",
    "        bounds = MAZE_BOUNDS[self.env_name]\n",
    "\n",
    "        observations = observations + 0.5\n",
    "        if len(bounds) == 2:\n",
    "            _, scale = bounds\n",
    "            observations /= scale\n",
    "        elif len(bounds) == 4:\n",
    "            _, iscale, _, jscale = bounds\n",
    "            observations[:, 0] /= iscale\n",
    "            observations[:, 1] /= jscale\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unrecognized bounds for {self.env_name}: {bounds}\")\n",
    "\n",
    "        if conditions is not None:\n",
    "            conditions /= scale\n",
    "        return super().renders(observations, conditions, **kwargs)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
